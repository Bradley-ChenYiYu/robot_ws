#!/usr/bin/env python3

import rclpy
from rclpy.node import Node
import configparser
import openai
import tempfile
import os
import requests
import pyaudio
import wave
from playsound import playsound
import speech_recognition as sr

class ChatbotNode(Node):
    def __init__(self):
        super().__init__('chatbot_node')

        # è®€å– API é‡‘é‘°
        config = configparser.ConfigParser()
        config.read('/home/jason9308/robot_ws/src/chatbot/config.ini')
        self.api_key = config['API']['api_key']
        openai.api_key = self.api_key

        # é—œéµè©ï¼šèªªäº†é€™äº›è©±å°±æœƒé€€å‡ºèŠå¤©
        self.exit_keywords = ["çµæŸèŠå¤©", "é€€å‡º", "å†è¦‹", "æ°æ°", "åœæ­¢å°è©±", "æ‹œæ‹œ"]

        # é—œéµè©ï¼šé€™äº›è©±æœƒè¢«è¦–ç‚ºèƒŒæ™¯éŸ³ï¼Œç•¥é
        self.blacklist_keywords = [
            "å­—å¹•byç´¢å…°å¨…",
            "è«‹ä¸åé»è´Š", "è¯·ä¸åç‚¹èµ",
            "è¨‚é–±", "è®¢é˜…", 
            "æ‰“èµæ”¯æŒ", "æ‰“è³æ”¯æŒ", 
            "æ˜é¡èˆ‡é»é»æ¬„ç›®", "æ˜é•œä¸ç‚¹ç‚¹æ ç›®",
            "å­—å¹•"
        ]
        self.get_logger().info("ğŸ¤– Chatbot å·²å•Ÿå‹•ï¼Œç­‰å¾…èªéŸ³è¼¸å…¥...")
        self.chat_loop()

    def chat_loop(self):
        while rclpy.ok():
            # audio_path = self.smart_record_audio()
            # text = self.transcribe_audio(audio_path)
            text = self.listen_and_transcribe()

            if text is None:
                self.get_logger().warn("è¾¨è­˜å¤±æ•—ï¼Œè«‹å†è©¦ä¸€æ¬¡ã€‚")
                continue

            self.get_logger().info(f"ä½ èªªï¼š{text}")

            if any(keyword in text for keyword in self.exit_keywords):
                self.get_logger().info("ğŸ›‘ åµæ¸¬åˆ°çµæŸé—œéµè©ï¼ŒçµæŸèŠå¤©")
                break

            if any(keyword in text for keyword in self.blacklist_keywords):
                self.get_logger().warn(f"âš ï¸ åµæ¸¬åˆ°èƒŒæ™¯èª¤è¾¨è­˜å…§å®¹ï¼Œç•¥éï¼š{text}")
                continue

            response = self.ask_gpt(text)
            self.speak_response(response)

        self.destroy_node()
        rclpy.shutdown()


    def listen_and_transcribe(self):
        recognizer = sr.Recognizer()
        recognizer.pause_threshold = 1.2
        # recognizer.energy_threshold = 600
        with sr.Microphone() as source:
            self.get_logger().info("ğŸ™ï¸ ç­‰å¾…ä½ èªªè©±...")
            recognizer.adjust_for_ambient_noise(source)
            audio = recognizer.listen(source)
            self.get_logger().info("ğŸ›‘ åµæ¸¬åˆ°ä½ è¬›å®Œè©±ï¼Œé–‹å§‹è¾¨è­˜...")

            # è¨ˆç®—éŒ„éŸ³é•·åº¦
            duration = len(audio.frame_data) / (audio.sample_rate * audio.sample_width)
            self.get_logger().info(f"ğŸ“ éŒ„éŸ³é•·åº¦ï¼š{duration:.2f} ç§’")

            if duration < 1.0:
                self.get_logger().warn("âš ï¸ éŒ„éŸ³å¤ªçŸ­ï¼Œå¯èƒ½æ˜¯é›œéŸ³ï¼Œç•¥éæ­¤æ¬¡è¼¸å…¥")
                return None

            try:
                text = recognizer.recognize_google(audio, language="zh-TW")
                return text
            except sr.UnknownValueError:
                self.get_logger().warn("âŒ èªéŸ³è¾¨è­˜å¤±æ•—ï¼ˆç„¡æ³•ç†è§£èªéŸ³ï¼‰")
                return None
            except sr.RequestError as e:
                self.get_logger().error(f"âŒ èªéŸ³è¾¨è­˜æœå‹™éŒ¯èª¤ï¼š{e}")
                return None



    def ask_gpt(self, user_input):
        messages = [
            {"role": "system", 
             "content": (
                "ä½ æ˜¯ä¸€ä½æº«æŸ”è¦ªåˆ‡çš„èªéŸ³èŠå¤©å¤¥ä¼´ï¼Œåƒæ˜¯ç…§é¡§é•·è€…çš„è­·ç†å“¡ï¼Œ"
                "ä¹Ÿåƒæ˜¯ä»–å€‘é—œå¿ƒé«”è²¼çš„å­«å­æˆ–å­«å¥³ã€‚\n"
                "è«‹ç”¨ç°¡å–®ã€æ…¢ä¸€é»çš„ä¸­æ–‡èªªè©±ï¼Œèªæ°£æº«å’Œã€è¦ªåˆ‡ï¼Œè®“äººæ„Ÿè¦ºæº«æš–ã€‚\n"
                "ä½ çš„ç›®çš„æ˜¯é™ªä¼´é•·è€…ï¼Œè·Ÿä»–å€‘èŠèŠå¤©ã€å›æ‡‰ä»–å€‘çš„æƒ…ç·’ï¼Œè®“ä»–å€‘è¦ºå¾—è¢«å‚¾è½å’Œé—œå¿ƒã€‚\n"
                "å¯ä»¥å•å€™ã€é—œå¿ƒä»–å€‘çš„æ—¥å¸¸ï¼Œä¹Ÿå¯ä»¥å›ç­”ä¸€äº›ç°¡å–®çš„ç”Ÿæ´»è©±é¡Œã€‚\n"
                "ä¸è¦è¬›å¤ªè¤‡é›œçš„å…§å®¹ï¼Œä¹Ÿä¸è¦æåˆ°ä½ æ˜¯ AIã€æ©Ÿå™¨äººæˆ–è™›æ“¬è§’è‰²ã€‚\n"
                "æ¯æ¬¡å›æ‡‰è«‹æ§åˆ¶åœ¨ 1~2 å¥è©±ä¹‹å…§ï¼Œè®“å°è©±ç¯€å¥è‡ªç„¶ã€‚"
                "æœ€é‡è¦çš„æ˜¯ æˆ‘å¸Œæœ›ä½ çš„å°è©±è‡ªç„¶ä¸€é» åƒæ˜¯ä¸€èˆ¬äººçš„å°è©±ä¸€æ¨£\n"
            )

            },

            {"role": "user", "content": user_input}
        ]

        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=messages
        )
        reply = response.choices[0].message.content.strip()
        self.get_logger().info(f"ğŸ§  GPT å›è¦†ï¼š{reply}")
        return reply

    def speak_response(self, text):
        tts_url = "https://api.openai.com/v1/audio/speech"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": "tts-1",
            "input": text,
            # "voice": "shimmer",
            # "voice": "nova",
            # "voice": "alloy",
            # "voice": "fable",
            # "voice": "onyx",
            "voice": "echo",
            "response_format": "mp3"
        }

        response = requests.post(tts_url, headers=headers, json=payload)

        if response.status_code == 200:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
                tmp_file.write(response.content)
                tmp_file_path = tmp_file.name

            self.get_logger().info("ğŸ”Š æ’­æ”¾èªéŸ³å›è¦†ä¸­...")
            playsound(tmp_file_path)
            os.remove(tmp_file_path)
        else:
            self.get_logger().error(f"TTS å¤±æ•—ï¼š{response.status_code} - {response.text}")

    # def record_audio(self, filename="temp_audio.wav", duration=5):
    #     # ä½¿ç”¨ PyAudio éŒ„éŸ³
    #     FORMAT = pyaudio.paInt16
    #     CHANNELS = 1
    #     RATE = 16000
    #     CHUNK = 1024
    #     audio = pyaudio.PyAudio()

    #     stream = audio.open(format=FORMAT, channels=CHANNELS,
    #                         rate=RATE, input=True,
    #                         frames_per_buffer=CHUNK)

    #     self.get_logger().info("ğŸ™ï¸ é–‹å§‹éŒ„éŸ³...")
    #     frames = []

    #     for _ in range(0, int(RATE / CHUNK * duration)):
    #         data = stream.read(CHUNK)
    #         frames.append(data)

    #     self.get_logger().info("ğŸ›‘ éŒ„éŸ³çµæŸ")

    #     stream.stop_stream()
    #     stream.close()
    #     audio.terminate()

    #     # å„²å­˜ç‚º wav æª”
    #     wf = wave.open(filename, 'wb')
    #     wf.setnchannels(CHANNELS)
    #     wf.setsampwidth(audio.get_sample_size(FORMAT))
    #     wf.setframerate(RATE)
    #     wf.writeframes(b''.join(frames))
    #     wf.close()

    #     return filename
    
    # def smart_record_audio(self, filename="temp_audio.wav"):
    #     recognizer = sr.Recognizer()
    #     recognizer.energy_threshold = 6000 
    #     with sr.Microphone() as source:
    #         self.get_logger().info("ğŸ™ï¸ ç­‰å¾…ä½ èªªè©±...")
    #         recognizer.adjust_for_ambient_noise(source)
    #         audio = recognizer.listen(source)
    #         self.get_logger().info("ğŸ›‘ åµæ¸¬åˆ°ä½ è¬›å®Œè©±ï¼ŒéŒ„éŸ³å®Œæˆ")

    #         # ğŸ§  è¨ˆç®—éŒ„éŸ³é•·åº¦ï¼ˆç§’ï¼‰
    #         duration = len(audio.frame_data) / (audio.sample_rate * audio.sample_width)
    #         self.get_logger().info(f"ğŸ“ éŒ„éŸ³é•·åº¦ï¼š{duration:.2f} ç§’")

    #         # âš ï¸ è‹¥å¤ªçŸ­å‰‡ç•¥é
    #         if duration < 2.0:
    #             self.get_logger().warn("âš ï¸ éŒ„éŸ³å¤ªçŸ­ï¼Œå¯èƒ½æ˜¯é›œéŸ³ï¼Œç•¥éæ­¤æ¬¡è¼¸å…¥")
    #             return None

    #         with open(filename, "wb") as f:
    #             f.write(audio.get_wav_data())
    #     return filename

    # def transcribe_audio(self, audio_path):
    #     try:
    #         audio_file = open(audio_path, "rb")
    #         transcript = openai.Audio.transcribe(
    #             model="whisper-1",
    #             file=audio_file,
    #             language="zh"
    #         )
    #         return transcript["text"]
    #     except Exception as e:
    #         self.get_logger().error(f"èªéŸ³è½‰æ–‡å­—å¤±æ•—ï¼š{e}")
    #         return None


def main(args=None):
    rclpy.init(args=args)
    node = ChatbotNode()
    # rclpy.spin(node)

if __name__ == '__main__':
    main()
